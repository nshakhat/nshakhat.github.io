Alarms in Ceilometer 
What fields does Alarm have?


Let’s consider the following alarm:


Mool@node-118:~/# ceilometer alarm-show 4a02a99b-d5ea-474d-a442-3faf2abdab11
+---------------------------+--------------------------------------------------------------------------+
| Property                  | Value                                                                    |
+---------------------------+--------------------------------------------------------------------------+
| alarm_actions             | [u'https://10.140.163.21:8000/v1/signal/arn%3Aopenstack%3Aheat%3A%3Ab96c |
|                           | 5de79b144880968cff78ab4f294e%3Astacks%2Fheatdebug%2F9fcd1986-8949-464b-b |
|                           | 518-5ae0ad53906c%2Fresources%2Fscale_up_policy?Timestamp=2016-02-24T08%3 |
|                           | A48%3A44Z&SignatureMethod=HmacSHA256&AWSAccessKeyId=89622617e1d8427bb5a5 |
|                           | 0dc686ec45b6&SignatureVersion=2&Signature=zuQPK6MBBzF2We6yqNAWsdz6kvg5A0 |
|                           | 6rLr%2FN%2VqVqKhY%3D']                                                   |
| alarm_id                  | 4a02a99b-d0ea-474d-a452-3faf2abdab11                                     |
| comparison_operator       | gt                                                                       |
| description               | Scale-up if the average CPU > 50% for 1 minute                           |
| enabled                   | True                                                                     |
| evaluation_periods        | 1                                                                        |
| exclude_outliers          | False                                                                    |
| insufficient_data_actions | []                                                                       |
| meter_name                | cpu_util                                                                 |
| name                      | heatdebug-cpu_alarm_high-edf4fjwysz37                                    |
| ok_actions                | []                                                                       |
| period                    | 60                                                                       |
| project_id                | b96c5de79b144880968cff58ab4f294e                                         |
| query                     | metadata.user_metadata.stack == 9fcd1986-8959-464b-b518-5ae0ad53906c     |
| repeat_actions            | True                                                                     |
| state                     | ok                                                                       |
| statistic                 | avg                                                                      |
| threshold                 | 50.0                                                                     |
| type                      | threshold                                                                |
| user_id                   | 0b77594b4ff14f699286328064f21aff                                         |
+---------------------------+--------------------------------------------------------------------------+




alarm _actions, insufficient_data actions, ok_actions
         
          All these actions are the only instrument to make Heat aware of different state of alarm. When Heat “receives” the message, it starts to do the defined actions. What should happen is defined in Heat, so Ceilometer has nothing to do with it. It’s possible to write entries to the log using log://.
  More info here https://wiki.openstack.org/wiki/Ceilometer/Alerting#Alarm_Action_Endpoint_definition


     2. Type
    Let’s consider 2 alarm types for now: combination and threshold. The “combination” one is based on the “threshold” actually.  For example, it’s possible to specify that a combination alarm should go to ALARM state if alarm_1 AND alarm_2 are in ALARM. “AND” is a comparison operator between alarms. Only “AND” or “OR” may be used. 
    In the example, we use type=threshold. 


3. threshold, statistic, query, period, meter_name, evaluation_periods, comparison_operator
    All the parameters above describes what data should be retrieved from Ceilometer database and how it should be done. To get the data, “statistics” API request is used. 
“evaluation_periods” determines how many periods should be taken into account during alarm evaluation. “period” means how long, in seconds, each period should be. During one evaluation, in alarm evaluator we should receive as many statistics objects, as many  “evaluation_periods” we have. For example, 


evaluation_periods = 3
period = 60
statistics request sent by evaluator will look like the following: 


  $ ceilometer statistics -m meter_name -q “timestamp > NOW - evaluation_period * period; timestamp<= NOW; query” --period 60
	As a result of this query alarm evaluator should receive 3 Statistics objects. If it gets less, alarm will go to “insufficient data” state.


Each Statistics object looks as following:
{
    "avg": 4.5,
    "count": 10,
    "duration*": 300.0,
    "duration_end*": "2013-01-04T16:47:00",
    "duration_start*": "2013-01-04T16:42:00",
    "max": 9.0,
    "min": 1.0,
    "period": 7200,                                 
    "period_end": "2013-01-04T18:00:00",
    "period_start": "2013-01-04T16:00:00",
    "sum": 45.0,
    "unit": "GiB"
}
* “Duration” is the interval in seconds between samples during the period. If we have two samples within “period_start” and “period_end”, “duration_start” will be a timestamp of the first message and “duratoin_end” - the second.


So, we have several statistics at once. That’s why we need to have “statistics”, “threshold” and “comparison_operator”. Evaluator needs this information to know what statistics among avg, sum, min, max, and count should be chosen and with what threshold it should be compared with “comparison_operator”. 
 	If we have evaluation_periods more than 1, what are the rules of transition from one state to another? So, if we in “insufficient data”, the latest period wins. For example, if we get [above_threshold, below_threshold, above_threshold], the alarm will be moved to ALARM state because it is a trend. If the state is “OK” or “ALARM”, the alarm will be moved to another state only if all periods have the same comparison results, i.e. [above_threshold, above_threshold, above_threshold] => ALARM or [below_threshold, below_threshold, below_threshold] => OK.
The “query” parameter is just an additional filtering for statistics request. Heat uses this to define the stack_id. Each Ceilometer measurement (Sample) is kept in database with corresponding resource metadata. For example, each Sample of cpu-metric contains the information about the vm it was taken from; a Sample of network.incoming.bytes contains the information about  the virtual interface and so on. So, Ceilometer may be told to consider Samples those resource_metadata has a particular field and value. It is always used for autoscaling.
“meter_name” is a metric we are interested in. Strictly speaking, we may use any metric we want here. The thing that should be kept in mind is that notification-based metrics are not predictable and it’s unlikely to avoid “insufficient data”. So, if we are talking about autoscaling, you should choose polling-based metrics. See “origin” in this table http://docs.openstack.org/admin-guide-cloud/telemetry-measurements.html. 




“Insufficient data” troubleshooting


The reason of “insufficient data” is one: we don’t have samples within an interval. 
So, when we get this result, we need to be sure that the configuration we use is correct:
If alarms are based on polling metrics, “period” <= interval from pipeline.yaml file for the metric we use. Because if we poll once in 600 seconds, we cannot get new data every 60 seconds for evaluation
If alarms are based on notification-based metrics, we cannot avoid “insufficient data” because notifications are sent when we create a resource. If there is no any schedule, we just cannot define the “period”


Also, there may be some reasons why data is not available:
Agent responsible for metrics collection doesn’t work. For autoscaling, we usually use instance-related metrics. So, be sure that compute agent is running and get the data.
The service the agents measure, is not available. For autoscaling, we ask Nova API to provide the list of instances. It means that if Nova doesn’t response, we cannot get any data.
Any authorization problems may cause problems.
Message broker is not available. Ceilometer uses RabbitMQ to send measurements to db. If it’s broken, we cannot write the measurement => “insufficient data”
Lag in message processing. It may be caused by several reasons. Collector-related queue (metering.sample) in RabbitMQ are processed slow by collector, MongoDB becomes unavailable (NotOkForStorage error). So, eventually the messages are written to db, but when evaluator needed this, it wasn’t there.
Ceilometer API returns errors. Actually, the requests used during the autoscaling have a lot of filters, but anyway something may go wrong. For example, in Juno it is possible to run out of threads in API server. 

