---
layout: post
title: "Alarms in OpenStack Telemetry"
date: 2016-12-5
---

<h2> Introduction </h2>
Telemetry alarming is the crucial part for Heat autoscaling feature. It used to be a part of Ceilometer,
but starting from Mitaka was moved to the Aodh project. This movement was smooth because ceilometer alarming 
API was supported for quite a while. Now, Alarming lives only in Aodh. There are several alarm types supported 
in Aodh, but this blogpost is about threshold ones - the type used during Heat autoscaling. The purpose of this post 
is to describe all fields to make it easy to understand what is all about.

<h2> Which fields does Alarm have? </h2>
To start with, let's take a look on alarm using the command
<code>
aodh alarm show 4a02a99b-d0ea-474d-a452-3faf2abdab11
</code>

| Property                  | Value                                             |
|---------------------------|:--------------------------------------------------|
| alarm_actions             | [u'https://10.140.163.21:8000/v1/signal/arn%3Aope |
|                           |  nstack%3Aheat%3A%3Ab96c5de79b1448......]         |
| alarm_id                  | 4a02a99b-d0ea-474d-a452-3faf2abdab11              |
| comparison_operator       | gt                                                |
| description               | Scale-up if the average CPU > 50% for 1 minute    |
| enabled                   | True                                              |
| evaluation_periods        | 1                                                 |
| exclude_outliers          | False                                             |
| insufficient_data_actions | []                                                |
| meter_name                | cpu_util                                          |
| name                      | heatdebug-cpu_alarm_high-edf4fjwysz37             |
| ok_actions                | []                                                |
| period                    | 60                                                |
| project_id                | b96c5de79b144880968cff58ab4f294e                  |
| query                     | metadata.user_metadata.stack == 9fcd1986-8959-... |
| repeat_actions            | True                                              |
| state                     | ok                                                |
| statistic                 | avg                                               |
| threshold                 | 50.0                                              |
| type                      | threshold                                         |
| user_id                   | 0b77594b4ff14f699286328064f21aff                  |



<h2> alarm _actions, insufficient_data actions, ok_actions </h2>
         
<p> All these actions are the only instrument to make Heat aware of different state of alarm. When Heat “receives” the message, it starts to do some actions. What exactly should happen is defined in Heat template, so neigher Ceilometer nor Aodh have nothing to do with it. It’s possible to write entries to the log using log:// to track what's going on.
  More info in <a href="https://wiki.openstack.org/wiki/Ceilometer/Alerting#Alarm_Action_Endpoint_definition" title="Search">official docs</a>.
 </p>


<h2> Type </h2>

<p> 
Aodh provides several types of alarms: combination, threshold, composite, event and gnocchi. 
</p>
<p>
"Threshold" is a "basic" one and we will continue looking into this later in this post. The “combination” one is based on the “threshold” actually.  For example, it’s possible to specify that a combination alarm should go to ALARM state if alarm_1 AND alarm_2 are in ALARM. “AND” is a comparison operator between alarms. Only "AND" or "OR" may be used. "Composite" alarm type has been created recently because a "combination" type was confusing sometimes.
</p>
<p>
"Event" type uses Ceilometer Event API or Panko API for its evaluation. It operats not with Ceilometer Samples, but with Events. 
</p>
<p>
"Gnocchi" type is used if Ceilometer uses Gnocchi as its database. It's one more interesting story ;)
</p>
<p>
Later on, we will talk only about Threshold alarm.
 </p>

<h2> threshold, statistic, query, period, meter_name, evaluation_periods, comparison_operator </h2>
<p> All the parameters above describes what data should be retrieved from Ceilometer database and how it should be done. To get the data, Ceilometer “statistics” API request is used. Thus, on this step Aodh communicates with Ceilometer. 
</p>
<p>
“evaluation_periods” determines how many periods should be taken into account during alarm evaluation. “Period” means how long, in seconds, each period should be. During one evaluation, in alarm evaluator we should receive as many statistics objects, as many  “evaluation_periods” we have. For example, 
</p>
<p>
Statistics request with parameters evaluation_periods = 3 and period = 60 sent by evaluator will look like the following: 
</p>
<code>
  $ ceilometer statistics -m meter_name -q “timestamp > NOW - evaluation_period * period; timestamp <= NOW; query” --period 60
</code>
<p>
As a result of this query alarm evaluator should receive 3 Ceilometer Statistics objects. If it gets less, alarm will go to “insufficient data” state.
</p>

<p>Each Statistics object looks as following (note that each one contains all possible statistics functions): </p>

<code>
{
    "avg": 4.5,
    "count": 10,
    "duration*": 300.0,
    "duration_end*": "2013-01-04T16:47:00",
    "duration_start*": "2013-01-04T16:42:00",
    "max": 9.0,
    "min": 1.0,
    "period": 7200,                                 
    "period_end": "2013-01-04T18:00:00",
    "period_start": "2013-01-04T16:00:00",
    "sum": 45.0,
    "unit": "GiB"
}
</code>
<p>
* “Duration” is the interval in seconds between samples during the period. If we have two samples within “period_start” and “period_end”, “duration_start” will be a timestamp of the first message and “duratoin_end” - the second.
</p>
<p>
So, we have several statistics function values at once. That’s why we need to have “statistics”, “threshold” and “comparison_operator”. Evaluator needs this information to know what statistics among avg, sum, min, max, and count should be chosen and with what threshold it should be compared with “comparison_operator”. 
</p>
<p>
If we have evaluation_periods more than 1, what are the rules of transition from one state to another? So, if we in “insufficient data”, the latest period wins. For example, if we get [above_threshold, below_threshold, above_threshold], the alarm will be moved to ALARM state because it is a trend. If the state is “OK” or “ALARM”, the alarm will be moved to another state only if all periods have the same comparison results, i.e. [above_threshold, above_threshold, above_threshold] => ALARM or [below_threshold, below_threshold, below_threshold] => OK.
</p>
<p>
The “query” parameter is just an additional filtering for statistics request. Heat uses this to define the stack_id. Each Ceilometer measurement (Sample) is kept in database with corresponding resource metadata. For example, each Sample of cpu-metric contains information about the vm it was taken from; a Sample of network.incoming.bytes contains the information about  the virtual interface and so on. So, Ceilometer may be told to consider Samples those resource_metadata has a particular field and value. It is always used for autoscaling.
</p>
<p>
“meter_name” is a metric we are interested in. Strictly speaking, we may use any metric we want here. The thing that should be kept in mind is that notification-based metrics are not predictable and it’s unlikely to avoid “insufficient data”. So, if we are talking about autoscaling, you should choose polling-based metrics. See “origin” in this table http://docs.openstack.org/admin-guide-cloud/telemetry-measurements.html. 
</p>

<h2> “Insufficient data” troubleshooting </h2>
<ol>
The reason of “insufficient data” is one: we don’t have samples within an interval. 
So, when we get this result, we need to be sure that the configuration we use is correct:
<li> If alarms are based on polling metrics, “period” <= interval from pipeline.yaml file for the metric we use. Because if we poll once in 600 seconds, we cannot get new data every 60 seconds for evaluation
</li>
<li>
If alarms are based on notification-based metrics, we cannot avoid “insufficient data” because notifications are sent when we create a resource. If there is no any schedule, we just cannot define the “period”
</li>
</ol>
<ol>
There may be some reasons why data is not available:
<li>
Agent responsible for metrics collection doesn’t work. For autoscaling, we usually use instance-related metrics. So, be sure that compute agent is running and get the data.
</li>
<li>
The service the agents measure, is not available. For autoscaling, we ask Nova API to provide the list of instances. It means that if Nova doesn’t response, we cannot get any data.
</li>
<li>
Any authorization problems may cause problems.
</li>
<li>
Message broker is not available. Ceilometer uses RabbitMQ to send measurements to db. If it’s broken, we cannot write the measurement => “insufficient data”
</li>
<li>
Lag in message processing. It may be caused by several reasons. Collector-related queue (metering.sample) in RabbitMQ are processed slow by collector, MongoDB becomes unavailable (NotOkForStorage error). So, eventually the messages are written to db, but when evaluator needed this, it wasn’t there.
</li>
<li>
Ceilometer API returns errors. Actually, the requests used during the autoscaling have a lot of filters, but anyway something may go wrong. For example, in Juno it is possible to run out of threads in API server. 
</li>
<ol>
